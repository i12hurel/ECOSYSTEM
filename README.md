# ECOSYSTEM-MODULADO

Este proyecto contiene un sistema de interpretaciÃ³n de modelos de machine learning utilizando tÃ©cnicas como LIME, SHAP y ANCHOR, implementado con CrewAI y otros mÃ³dulos de IA explicable.

## Estructura del proyecto

```
ECOSYSTEM-MODULADO/
â”œâ”€â”€ src/                          # CÃ³digo fuente
â”‚   â”œâ”€â”€ chatInterpreterLLM/
â”‚       â”œâ”€â”€ crew/
â”‚       â”œâ”€â”€ env/
â”‚       â”œâ”€â”€ knowledge/
â”‚       â”œâ”€â”€ tasks/
â”‚       â”œâ”€â”€ tools/
â”‚       â””â”€â”€ training/
â”œâ”€â”€ requirements.txt              # Dependencias del proyecto
â”œâ”€â”€ .vscode/settings.json          # ConfiguraciÃ³n recomendada para VSCode
â””â”€â”€ README.md                      # Instrucciones
```

## ğŸš€ CÃ³mo empezar

### 1. Clona el repositorio

```bash
git clone https://github.com/tu-usuario/ECOSYSTEM-MODULADO.git
cd ECOSYSTEM-MODULADO
```

### 2. Crea un entorno virtual

```bash
python -m venv venv
```

### 3. Activa el entorno virtual

* En **Windows**:

  ```bash
  venv\Scripts\activate
  ```
* En **Mac/Linux**:

  ```bash
  source venv/bin/activate
  ```

### 4. Instala las dependencias

```bash
pip install -r requirements.txt
```

### 5. Configura Visual Studio Code (VSCode)

#### Paso 1: Selecciona el intÃ©rprete Python

* `Ctrl+Shift+P` â†’ **Python: Select Interpreter** â†’ Elige el Python de `./venv`.

#### Paso 2: AÃ±ade configuraciÃ³n para los imports

AsegÃºrate de tener este archivo en `.vscode/settings.json`:

```json
{
  "python.analysis.extraPaths": [
    "./src"
  ],
  "python.defaultInterpreterPath": "./venv/Scripts/python.exe"
}
```

*(En Mac/Linux, la ruta es `./venv/bin/python`.)*

Esto permite que VSCode reconozca correctamente los imports relativos desde `src/`.

### 6. Ejecutar el proyecto

Desde la raÃ­z del proyecto:

```bash
python -m src.chatInterpreterLLM.main
```

---

## âœ… Requisitos

* Python 3.10 o superior
* Visual Studio Code (opcional, pero recomendado)

---

## âš ï¸ Notas importantes

* **No subas el `venv/`** a GitHub. Usa `.gitignore`.
* AsegÃºde tu conexiÃ³n a internet para usar CrewAI con los modelos LLM.

---
